{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this Notebook we calculate the ratio of pixels that are annotated as positive in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First for $256 \\times 256$ sized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hubmap.dataset import TrainDataset\n",
    "import hubmap.dataset.transforms as T\n",
    "from hubmap.data import DATA_DIR\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose_256 = T.Compose([T.ToTensor(), T.Resize((256, 256))])\n",
    "tset_256 = TrainDataset(DATA_DIR, transform=compose_256, with_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_pixels_256 = []\n",
    "gl_pixels_256 = []\n",
    "uns_pixels_256 = []\n",
    "bg_pixels_256 = []\n",
    "\n",
    "for _, target in tset_256:\n",
    "    bv_pixels_256.append((target[0, :, :]).sum())\n",
    "    gl_pixels_256.append((target[1, :, :]).sum())\n",
    "    uns_pixels_256.append((target[2, :, :]).sum())\n",
    "    bg_pixels_256.append((target[3, :, :]).sum())\n",
    "    \n",
    "bv_pixels_256 = np.array(bv_pixels_256)\n",
    "gl_pixels_256 = np.array(gl_pixels_256)\n",
    "uns_pixels_256 = np.array(uns_pixels_256)\n",
    "bg_pixels_256 = np.array(bg_pixels_256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pixels_per_mask_256 = 256 * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_per_image_ratio_256 = bv_pixels_256 / total_pixels_per_mask_256\n",
    "gl_per_image_ratio_256 = gl_pixels_256 / total_pixels_per_mask_256\n",
    "uns_per_image_ratio_256 = uns_pixels_256 / total_pixels_per_mask_256\n",
    "bg_per_image_ratio_256 = bg_pixels_256 / total_pixels_per_mask_256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_per_image_ratio_256_mean = np.mean(bv_per_image_ratio_256)\n",
    "gl_per_image_ratio_256_mean = np.mean(gl_per_image_ratio_256)\n",
    "uns_per_image_ratio_256_mean = np.mean(uns_per_image_ratio_256)\n",
    "bg_per_image_ratio_256_mean = np.mean(bg_per_image_ratio_256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_per_image_ratio_256_mean + gl_per_image_ratio_256_mean + uns_per_image_ratio_256_mean + bg_per_image_ratio_256_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_per_image_weight = 1 - bv_per_image_ratio_256_mean\n",
    "gl_per_image_weight = 1 - gl_per_image_ratio_256_mean\n",
    "uns_per_image_weight = 1 - uns_per_image_ratio_256_mean\n",
    "bg_per_image_weight = 1 - bg_per_image_ratio_256_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bv_per_image_weight: \", bv_per_image_weight)\n",
    "print(\"gl_per_image_weight: \", gl_per_image_weight)\n",
    "print(\"uns_per_image_weight: \", uns_per_image_weight)\n",
    "print(\"bg_per_image_weight: \", bg_per_image_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_per_image_weight + gl_per_image_weight + uns_per_image_weight + bg_per_image_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = 4 / (bv_per_image_weight + gl_per_image_weight + uns_per_image_weight + bg_per_image_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_per_image_weight_normed = normalizer * bv_per_image_weight\n",
    "gl_per_image_weight_normed = normalizer * gl_per_image_weight\n",
    "uns_per_image_weight_normed = normalizer * uns_per_image_weight\n",
    "bg_per_image_weight_normed = normalizer * bg_per_image_weight\n",
    "\n",
    "\n",
    "print(\"bv_per_image_weight_normed: \", bv_per_image_weight_normed)\n",
    "print(\"gl_per_image_weight_normed: \", gl_per_image_weight_normed)\n",
    "print(\"uns_per_image_weight_normed: \", uns_per_image_weight_normed)\n",
    "print(\"bg_per_image_weight_normed: \", bg_per_image_weight_normed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now for $512 \\times 512$ images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose_512 = T.Compose([T.ToTensor(), T.Resize((512, 512))])\n",
    "tset_512 = TrainDataset(DATA_DIR, transform=compose_512, with_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_pixels_512 = []\n",
    "gl_pixels_512 = []\n",
    "uns_pixels_512 = []\n",
    "bg_pixels_512 = []\n",
    "\n",
    "for _, target in tset_512:\n",
    "    bv_pixels_512.append((target[0, :, :]).sum())\n",
    "    gl_pixels_512.append((target[1, :, :]).sum())\n",
    "    uns_pixels_512.append((target[2, :, :]).sum())\n",
    "    bg_pixels_512.append((target[3, :, :]).sum())\n",
    "    \n",
    "bv_pixels_512 = np.array(bv_pixels_512)\n",
    "gl_pixels_512 = np.array(gl_pixels_512)\n",
    "uns_pixels_512 = np.array(uns_pixels_512)\n",
    "bg_pixels_512 = np.array(bg_pixels_512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pixels_per_mask_512 = 512 * 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_per_image_ratio_512 = bv_pixels_512 / total_pixels_per_mask_512\n",
    "gl_per_image_ratio_512 = gl_pixels_512 / total_pixels_per_mask_512\n",
    "uns_per_image_ratio_512 = uns_pixels_512 / total_pixels_per_mask_512\n",
    "bg_per_image_ratio_512 = bg_pixels_512 / total_pixels_per_mask_512\n",
    "\n",
    "bv_per_image_ratio_512_mean = np.mean(bv_per_image_ratio_512)\n",
    "gl_per_image_ratio_512_mean = np.mean(gl_per_image_ratio_512)\n",
    "uns_per_image_ratio_512_mean = np.mean(uns_per_image_ratio_512)\n",
    "bg_per_image_ratio_512_mean = np.mean(bg_per_image_ratio_512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bv_per_image_ratio_512_mean: \", bv_per_image_ratio_512_mean)\n",
    "print(\"gl_per_image_ratio_512_mean: \", gl_per_image_ratio_512_mean)\n",
    "print(\"uns_per_image_ratio_512_mean: \", uns_per_image_ratio_512_mean)\n",
    "print(\"bg_per_image_ratio_512_mean: \", bg_per_image_ratio_512_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We stop here, as the ratios are the same as for $256 \\times 256$ sized iamges."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
